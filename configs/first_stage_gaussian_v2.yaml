model:
  target: models.first_stage_kl_atom.AutoencoderKL
  base_learning_rate: 4.5e-06
  monitor: val/rec_loss
  monitor_mode: min
  params:
    embed_dim: 4
    lossconfig:
      target: losses.contperceptual.LPIPSWithDiscriminator
      params:
        disc_start: 50001
        kl_weight: 1.0e-06
        disc_weight: 0.5
    encoder_config:
      target: modules.e2sr.s1_v6.GAPEncoder
      params:
        in_channels: 6
        ch: 64
        ch_mult: [1, 2, 2, 4]
        num_res_blocks: 2
        attn_resolutions: []
        z_channels: 4
        double_z: true
    decoder_config:
      target: modules.e2sr.s1_v7.GAPDecoder
      params:
        ch: 64
        out_ch: 3
        ch_mult: [1, 1, 1, 1]
        num_res_blocks: 2
        attn_resolutions: []
        z_channels: 4
        in_channels: 3
        num_sr_modules: [12, 12, 12, 12]
        # GaussianSplattingV2 配置
        use_gaussian_v2: true        
        gaussian_v2_hidden_dim: 256   
        gaussian_v2_dict_size: 729     
        gaussian_v2_use_gsplat: false  
        gaussian_v2_upsample_factor: 2 

data:
  target: data.datamodule.DataModuleFromConfig
  params:
    batch_size: 4
    num_workers: 8
    wrap: false
    train:
      target: data.downsampled_dataset.MultiScaleDownsampledDataset
      params:
        datapath: load/AID_split/train/HR
        min_scale: 1
        max_scale: 8
        is_train: true
        lr_img_sz: 48
        cache: memory
        data_length: 4000
        batch_size: 4
    validation:
      target: data.downsampled_dataset.DownsampledDataset
      params:
        datapath: load/AID_split/train/HR
        scale: 4
        is_train: false
        first_k: 2
        cache: memory

#################################
##  Configs for the Lightning  ##
#################################
lightning:
  trainer:
    max_epochs: 1000
    reload_dataloaders_every_n_epochs: 1
