model:
  target: models.first_stage_kl_finetune.AutoencoderKLFinetune
  base_learning_rate: 4.5e-06
  monitor: val/rec_loss
  monitor_mode: min
  params:
    embed_dim: 4
    ckpt_path: logs/epoch=779-best.ckpt
    ignore_keys: ['decoder.upsampler', 'loss']
    freeze_encoder: true
    freeze_decoder_base: true
    freeze_loss: true
    lossconfig:
      target: losses.contperceptual.LPIPSWithDiscriminator
      params:
        disc_start: 50001
        kl_weight: 1.0e-06
        disc_weight: 0.5
    encoder_config:
      target: modules.e2sr.s1_v6.GAPEncoder
      params:
        in_channels: 6
        ch: 64
        ch_mult: [1, 2, 2, 4]
        num_res_blocks: 2
        attn_resolutions: []
        z_channels: 4
        double_z: true
    decoder_config:
      target: modules.e2sr.s1_v6.GAPDecoder
      params:
        ch: 64
        out_ch: 3
        ch_mult: [1, 1, 1, 1]
        num_res_blocks: 2
        attn_resolutions: []
        z_channels: 4
        in_channels: 3
        num_sr_modules: [12, 12, 12, 12]
        # ★ 使用 GaussianQuery 上采样器
        use_gaussian_query: true
        num_gaussians: 100
        gaussian_kernel_size: 7
        gaussian_hidden_dim: 256

data:
  target: data.datamodule.DataModuleFromConfig
  params:
    batch_size: 2
    num_workers: 8
    wrap: false
    train:
      target: data.downsampled_dataset.MultiScaleDownsampledDataset
      params:
        datapath: load/AID_split/train/HR
        min_scale: 1
        max_scale: 8
        is_train: true
        lr_img_sz: 48
        cache: memory
        data_length: 4000
        batch_size: 2
    validation:
      target: data.downsampled_dataset.MultiScaleDownsampledDatasetWithFixedHRSize
      params:
        datapath: load/AID_split/val/HR
        min_scale: 4
        max_scale: 4
        is_train: false
        hr_img_sz: 256
        cache: memory
        data_length: 2
        batch_size: 2

#################################
##  Configs for the Lightning  ##
#################################
lightning:
  trainer:
    max_epochs: 1000
    reload_dataloaders_every_n_epochs: 1
    accumulate_grad_batches: 2
    # num_sanity_val_steps: 0  # ← 跳过 sanity check
